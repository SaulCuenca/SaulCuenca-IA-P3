# -*- coding: utf-8 -*-
"""E°6_21110324_ProtectoIA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mrgsj_LnKxfveGw4k2c099Wzab6CQtZL
"""

import tensorflow as tf
from tensorflow import keras
import cv2
import numpy as np
import matplotlib.pyplot as plt


(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()  # loads the popular "mnist" training dataset

plt.imshow(x_train[0], cmap="gray")

plt.imshow(x_train[1], cmap="gray")

x_train[0].shape

28*28

x_train[0]

x_train = x_train/255.0
x_test = x_test/255.0

x_train = x_train/255.0

x_train[0]

encoder_input = keras.Input(shape=(28, 28, 1), name='img')
x = keras.layers.Flatten()(encoder_input)
encoder_output = keras.layers.Dense(64, activation="relu")(x)

encoder = keras.Model(encoder_input, encoder_output, name="encoder")


decoder_input = keras.layers.Dense(64, activation="relu")(encoder_output)
x = keras.layers.Dense(784, activation="relu")(decoder_input)
decoder_output = keras.layers.Reshape((28, 28, 1))(x)

optimizer = tf.keras.optimizers.legacy.Adam(lr=0.001)

autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')
autoencoder.summary()

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Supongamos que ya tienes tu modelo de autoencoder definido
autoencoder = Sequential()
# Agrega tus capas al modelo de autoencoder...

# Define el optimizador
opt = Adam(learning_rate=0.001)  # Puedes ajustar la tasa de aprendizaje según sea necesario

# Compila el modelo de autoencoder
autoencoder.compile(optimizer=opt, loss='mse')

autoencoder.fit(x_train, x_train, epochs=3, batch_size=32, validation_split=0.1)

example = encoder.predict([x_test[0].reshape(-1, 28, 28, 1)])[0]

print(example)

example.shape

64/784

plt.imshow(example.reshape((8,8)), cmap="gray")

plt.imshow(x_test[0], cmap="gray")

ae_out = autoencoder.predict([x_test[0].reshape(-1, 28, 28, 1)])[0]

plt.imshow(example.reshape((8,8)), cmap="gray")

import matplotlib.pyplot as plt

# Supongamos que x_test es tu conjunto de datos de prueba

for d in x_test[:5]:  # Muestra solo 5 ejemplos, siéntete libre de mostrar más o menos según desees
    # Ajusta las dimensiones si es necesario y realiza la predicción
    ae_out = autoencoder.predict(d.reshape(-1, 28, 28, 1))
    img = ae_out[0]

    # Muestra las imágenes utilizando Matplotlib
    plt.figure(figsize=(8, 4))

    # Imagen original
    plt.subplot(1, 2, 1)
    plt.imshow(d.reshape(28, 28), cmap='gray')
    plt.title('Original')
    plt.axis('off')

    # Imagen decodificada por el autoencoder
    plt.subplot(1, 2, 2)
    plt.imshow(img.reshape(28, 28), cmap='gray')
    plt.title('Decodificado')
    plt.axis('off')

    # Muestra la figura
    plt.show()

smaller = cv2.resize(x_test[0], (8,8))
back_to_original = cv2.resize(smaller, (28,28))
plt.imshow(smaller, cmap="gray")

plt.imshow(back_to_original, cmap="gray")